{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f40929-e1f5-41b6-a196-092848aae718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c6eb20-5633-46e2-b7be-fd2f647ab9a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-openai in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (0.3.14)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain) (0.3.54)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain) (2.11.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain-openai) (1.69.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/opt/certifi/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Cellar/jupyterlab/4.3.6/libexec/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU \"langchain[openai]\"\n",
    "%pip install -U langchain langchain-openai\n",
    "%pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "812c79ae-d8f0-405d-8334-8c89f286c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb92dd30-d8c6-4d78-89df-ce56ab141614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1492f925-1dcf-4cc1-b277-8f1cd9c88935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed6943bf-ee2d-48fb-bebb-8cb85ff3b628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web_paths': ['https://lilianweng.github.io/posts/2023-06-23-agent/'],\n",
       " 'requests_per_second': 2,\n",
       " 'default_parser': 'html.parser',\n",
       " 'requests_kwargs': {},\n",
       " 'raise_for_status': False,\n",
       " 'show_progress': True,\n",
       " 'bs_get_text_kwargs': {},\n",
       " 'bs_kwargs': {'parse_only': <SoupStrainer name=[] attrs=defaultdict(<class 'list'>, {'class': [<AttributeValueMatchRule string=post-content pattern=None function=None present=None>, <AttributeValueMatchRule string=post-title pattern=None function=None present=None>, <AttributeValueMatchRule string=post-header pattern=None function=None present=None>]}) string=[]>},\n",
       " 'session': <requests.sessions.Session at 0x10d439a90>,\n",
       " 'continue_on_failure': False,\n",
       " 'autoset_encoding': True,\n",
       " 'encoding': None,\n",
       " 'trust_env': False}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "703df346-2204-4733-a1fd-73e158f93913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> Number of char 43130\n"
     ]
    }
   ],
   "source": [
    "print(type(docs), 'Number of char' ,len(docs[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80ac4fa8-f868-4695-a40d-1fbc3632fca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105fb64-8364-4c01-931a-e1dd093822e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61568f5-a3be-403e-8a38-f6ca5582e50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132547c3-3f7e-462d-897a-1d9465c7a0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for leverage langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2104260-7138-457f-8686-aa2de369435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_retries=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e590725a-eb15-4a1f-b1dc-75f77cedba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "599ea593-1ea3-4e73-8b2f-824a3459112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdea5f2-7100-480b-bb24-689e4fe96183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa60e579-3175-499f-a6ed-59c6e730f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38c5052b-d726-4f6f-a858-e00de884913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb1c1a7a-e041-4b3a-848e-01a0e418397c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pull in module langchain.hub:\n",
      "\n",
      "pull(\n",
      "    owner_repo_commit: 'str',\n",
      "    *,\n",
      "    include_model: 'Optional[bool]' = None,\n",
      "    api_url: 'Optional[str]' = None,\n",
      "    api_key: 'Optional[str]' = None\n",
      ") -> 'Any'\n",
      "    Pull an object from the hub and returns it as a LangChain object.\n",
      "\n",
      "    :param owner_repo_commit: The full name of the prompt to pull from in the format of\n",
      "        `owner/prompt_name:commit_hash` or `owner/prompt_name`\n",
      "        or just `prompt_name` if it's your own prompt.\n",
      "    :param api_url: The URL of the LangChain Hub API. Defaults to the hosted API service\n",
      "        if you have an api key set, or a localhost instance if not.\n",
      "    :param api_key: The API key to use to authenticate with the LangChain Hub API.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(hub.pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a2603a-53a6-47a8-b28e-c2865e1dd657",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2126dba5-7b90-4765-8258-4644525cccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this particular prompt from the hub, is defining the variables Question: {question} Context: {context}  in its prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ce14d8-5c92-4956-a6f9-92336364ccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "034b398c-6175-45cf-b12f-7e45d789b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85ae31b2-99c9-4c8c-9c4d-ee5be1123d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langgraph.graph.state.CompiledStateGraph, langgraph.graph.state.StateGraph)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(graph),  type(graph_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5be6855-76a3-4aa5-ab96-ee4367e1d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(StateGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d71eff9b-5a0e-49b6-86cb-11adbe0c31a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Reference:hub | WebBaseLoader | Document | RecursiveCharacterTextSplitter | StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "854e8132-d924-49e9-944f-25c0e24e1c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Decomposition is the process of breaking down a complex task into smaller, more manageable steps. This can be achieved through techniques like Chain of Thought (CoT) prompting, which encourages models to think step by step, or by using task-specific instructions. It allows for better planning and execution by clarifying the logical relationships between tasks.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "357bf664-2f01-4fed-9303-a59bafbe8d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The conversation discusses the development of a Super Mario game in Python, focusing on the MVC architecture and keyboard controls. \n",
      "\n",
      "**Important points:**\n",
      "1. The game will be structured using MVC components, which need to be split into separate files.\n",
      "2. Clarification is needed on the specifics of the game, including level design, characters, and gameplay mechanics.\n",
      "3. Details regarding the implementation of keyboard controls, such as key mappings and input handling, are also required.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"Summarize the topics being discussed, and mention 3 important points from each topic\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3934150-e0e9-48f4-a6aa-b0ee95c907dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e461985-bfff-416c-a768-bb66ce81fa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article provides detailed instructions for writing code, focusing on implementing a software architecture step by step. It emphasizes the importance of laying out core classes, functions, and methods, along with their purposes, before presenting the complete code in a structured markdown format. The goal is to ensure that every aspect of the architecture is translated into functional code, starting from the entry point and moving through all related files.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"I want an answer in 10 lines. Summarize what is article is for.\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
